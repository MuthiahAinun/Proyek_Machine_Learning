{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda08150",
   "metadata": {
    "id": "TGyNMBnyGxsv"
   },
   "source": [
    "# Proyek Analisis Sentimen: [Youtube-Comments-dataset]\n",
    "- **Nama:** [Tsamarah Muthi'ah Abdullah]\n",
    "- **Email:** [a135xaf486@devacademy.id]\n",
    "- **ID Dicoding:** [a135xaf48]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c580a11",
   "metadata": {
    "id": "PkjP4X-lHP1v"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2aa24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 931
    },
    "id": "fUh0dCwlHnD7",
    "outputId": "0972e66b-bf1a-4287-f870-93a9f97bd38a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.160.0)\n",
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.165.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.38.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.24.2)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.69.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (4.25.6)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.1.31)\n",
      "Downloading google_api_python_client-2.165.0-py2.py3-none-any.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pandas, google-api-python-client\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "  Attempting uninstall: google-api-python-client\n",
      "    Found existing installation: google-api-python-client 2.160.0\n",
      "    Uninstalling google-api-python-client-2.160.0:\n",
      "      Successfully uninstalled google-api-python-client-2.160.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-api-python-client-2.165.0 pandas-2.2.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "89e98e9bd9e6453fbc24c427798b843d",
       "pip_warning": {
        "packages": [
         "googleapiclient"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Menginstall google API\n",
    "!pip install --upgrade google-api-python-client pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddef150",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwkllzT7zE1i",
    "outputId": "9cfc7d71-7a71-4aa4-f274-6dc6626dbce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.1\n",
      "    Uninstalling scipy-1.14.1:\n",
      "      Successfully uninstalled scipy-1.14.1\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10160545",
   "metadata": {
    "id": "I6Pw9OLlHXG7"
   },
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Conv1D, GlobalMaxPooling1D, Bidirectional, BatchNormalization\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Bidirectional, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e20cfcf",
   "metadata": {
    "id": "ENIdk__BiOJT"
   },
   "source": [
    "# Data Preprocessing dan Pembersihan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d24e5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wtg0gpXcjEH8",
    "outputId": "989917ae-6335-45eb-cf86-b19a94806ef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data: 85028\n"
     ]
    }
   ],
   "source": [
    "# Membaca dan Menampilkan informasi dataset\n",
    "dataset = pd.read_csv(\"NDsO1LT_0lw_youtube_comments.csv\")\n",
    "print(\"Jumlah data:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab030b60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ADwNxWVjWUx",
    "outputId": "43ecaad9-c519-4c54-ac8f-2d10b5d6773c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             username                                               text  \\\n",
      "0            @MrBeast  BEAST GAMES FINALE DROPS FEBRUARY 13TH! GO WAT...   \n",
      "1     @SultanRayyan-7                          Saya orang Indonesia ğŸ‡®ğŸ‡©ğŸ‡®ğŸ‡©   \n",
      "2  @MohamadrezaRezayy  Ù…Ø³ØªØ± Ø¨ÛŒØ³Øª Ø¹Ø²ÛŒØ² â¤ Ù„Ø·ÙØ§ Ø¯ÙˆØ¨Ù„Ù‡ ÙØ§Ø±Ø³ÛŒ Ø§ÛŒÙ† ÙˆÛŒØ¯ÛŒÙˆ Ø±Ø§...   \n",
      "3       @ILoveyou-954  à¦¬à¦¾à¦‚à¦²à¦¾à¦¦à§‡à¦¶ à¦†à¦¸à¦¬à§‡à¦¨ à¦•à¦¬à§‡ à¦ªà¦¾à¦¬à¦¨à¦¾ à¦œà§‡à¦²à¦¾à¦° à¦•à¦¿à¦›à§ à¦¦à§‡à¦–à¦¤à§‡ à¦šà¦¾à¦‡ ...   \n",
      "4     @Moneymakerarab  This is for girls listen to Dalida - Helwa ya ...   \n",
      "\n",
      "   likes          published_at  \n",
      "0  54600  2025-02-08T16:59:31Z  \n",
      "1      0  2025-03-19T21:51:42Z  \n",
      "2      0  2025-03-19T21:43:03Z  \n",
      "3      0  2025-03-19T21:34:32Z  \n",
      "4      0  2025-03-19T21:20:21Z  \n"
     ]
    }
   ],
   "source": [
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb94384",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gD1WeBk3jj4g",
    "outputId": "16f613eb-1838-4ade-e902-10fa235e1b6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informasi Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85028 entries, 0 to 85027\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   username      84982 non-null  object\n",
      " 1   text          85028 non-null  object\n",
      " 2   likes         85028 non-null  int64 \n",
      " 3   published_at  85028 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Informasi Dataset:\")\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c676c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilYCEbrKjv5n",
    "outputId": "0a992fb2-a75d-4d7d-b337-9c4e3e97cb54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistik Deskriptif:\n",
      "               likes\n",
      "count   85028.000000\n",
      "mean        9.727654\n",
      "std       744.702565\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         1.000000\n",
      "max    167348.000000\n"
     ]
    }
   ],
   "source": [
    "print('\\nStatistik Deskriptif:')\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3edd8c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GEaqaxe4j6Li",
    "outputId": "8b2da518-70f6-484b-feb4-6c0df3f6c85c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username        46\n",
      "text             0\n",
      "likes            0\n",
      "published_at     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mengecek jumlah missing values di setiap kolom\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754981f",
   "metadata": {
    "id": "ZTNC1ghpkkpa"
   },
   "outputs": [],
   "source": [
    "# Menghapus nilai kosong\n",
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1015b3",
   "metadata": {
    "id": "b5HYvwY0kn00"
   },
   "outputs": [],
   "source": [
    "# Menghapus duplikasi\n",
    "dataset.drop_duplicates(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f55b26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Mi_m65UkrwQ",
    "outputId": "26fa3624-060f-4202-db4e-a25025966e5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data setelah pembersihan:\n",
      "             username                                               text  \\\n",
      "0            @MrBeast  BEAST GAMES FINALE DROPS FEBRUARY 13TH! GO WAT...   \n",
      "1     @SultanRayyan-7                          Saya orang Indonesia ğŸ‡®ğŸ‡©ğŸ‡®ğŸ‡©   \n",
      "2  @MohamadrezaRezayy  Ù…Ø³ØªØ± Ø¨ÛŒØ³Øª Ø¹Ø²ÛŒØ² â¤ Ù„Ø·ÙØ§ Ø¯ÙˆØ¨Ù„Ù‡ ÙØ§Ø±Ø³ÛŒ Ø§ÛŒÙ† ÙˆÛŒØ¯ÛŒÙˆ Ø±Ø§...   \n",
      "3       @ILoveyou-954  à¦¬à¦¾à¦‚à¦²à¦¾à¦¦à§‡à¦¶ à¦†à¦¸à¦¬à§‡à¦¨ à¦•à¦¬à§‡ à¦ªà¦¾à¦¬à¦¨à¦¾ à¦œà§‡à¦²à¦¾à¦° à¦•à¦¿à¦›à§ à¦¦à§‡à¦–à¦¤à§‡ à¦šà¦¾à¦‡ ...   \n",
      "4     @Moneymakerarab  This is for girls listen to Dalida - Helwa ya ...   \n",
      "\n",
      "   likes          published_at  \\\n",
      "0  54600  2025-02-08T16:59:31Z   \n",
      "1      0  2025-03-19T21:51:42Z   \n",
      "2      0  2025-03-19T21:43:03Z   \n",
      "3      0  2025-03-19T21:34:32Z   \n",
      "4      0  2025-03-19T21:20:21Z   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  beast games finale drops february 13th go watc...  \n",
      "1                              saya orang indonesia   \n",
      "2  Ù…Ø³ØªØ± Ø¨ÛŒØ³Øª Ø¹Ø²ÛŒØ²  Ù„Ø·ÙØ§ Ø¯ÙˆØ¨Ù„Ù‡ ÙØ§Ø±Ø³ÛŒ Ø§ÛŒÙ† ÙˆÛŒØ¯ÛŒÙˆ Ø±Ø§ ...  \n",
      "3                    à¦¬à¦²à¦¦à¦¶ à¦†à¦¸à¦¬à¦¨ à¦•à¦¬ à¦ªà¦¬à¦¨ à¦œà¦²à¦° à¦•à¦› à¦¦à¦–à¦¤ à¦šà¦‡   \n",
      "4  this is for girls listen to dalida  helwa ya b...  \n"
     ]
    }
   ],
   "source": [
    "# Pembersihan teks\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join(c for c in text if c.isalnum() or c.isspace())\n",
    "    return text\n",
    "\n",
    "dataset['cleaned_text'] = dataset['text'].apply(clean_text)\n",
    "print(\"Data setelah pembersihan:\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d466f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocQOJSqMk5Nv",
    "outputId": "8de896c9-aebe-45d7-a35c-9bdd3b8b9bac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username        0\n",
      "text            0\n",
      "likes           0\n",
      "published_at    0\n",
      "cleaned_text    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mengecek kembali jumlah missing values di setiap kolom\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c0c2de",
   "metadata": {},
   "source": [
    "# SKEMA 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d61bc",
   "metadata": {
    "id": "nBwOOPI5lASL"
   },
   "source": [
    "# **2. Ekstraksi Fitur dan Pelabelan Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a686076",
   "metadata": {
    "id": "eJv-MtsUlHzI"
   },
   "source": [
    "Metode yang digunakan bebas sesuai dengan preferensi masing-masing peserta. Tahapan ini penting untuk mempersiapkan data sehingga dapat diolah lebih lanjut dalam proses pelatihan model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8fb8af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7Uvoet4lI9T",
    "outputId": "3bce9178-ec0a-4862-902d-631ef0faca56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi label:\n",
      "label\n",
      "netral     63766\n",
      "positif     4728\n",
      "negatif       69\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Melabeli komentar secara manual (positif, netral, negatif)\n",
    "def label_comment(text):\n",
    "    if any(word in text for word in [\"love\", \"great\", \"awesome\", \"good\", \"nice\", \"amazing\", \"fantastic\"]):\n",
    "        return \"positif\"\n",
    "    elif any(word in text for word in [\"hate\", \"bad\", \"awful\", \"worst\", \"terrible\", \"disgusting\", \"boring\"]):\n",
    "        return \"negatif\"\n",
    "    else:\n",
    "        return \"netral\"\n",
    "\n",
    "dataset['label'] = dataset['cleaned_text'].apply(label_comment)\n",
    "print(\"Distribusi label:\")\n",
    "print(dataset['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e19a81e",
   "metadata": {
    "id": "IqZS3KMplvFC"
   },
   "outputs": [],
   "source": [
    "# Encoding label\n",
    "label_encoder = LabelEncoder()\n",
    "dataset['label_encoded'] = label_encoder.fit_transform(dataset['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f9b56f",
   "metadata": {
    "id": "97mjHYpAmZKf"
   },
   "source": [
    "# **3. Pembangunan Model Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd5990",
   "metadata": {
    "id": "lXa9RkwLmd-C"
   },
   "source": [
    "Pilihan algoritma pelatihan ini haruslah sesuai dengan tujuan analisis sentimen yang ingin dicapai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a7a63a",
   "metadata": {
    "id": "5-Ui-xoToXXN"
   },
   "source": [
    "# Skema 1: LSTM dengan Tokenizer + Padding (80/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775abffc",
   "metadata": {
    "id": "1jBs_D849Vgh"
   },
   "source": [
    "**Algoritma:** Long Short-Term Memory (LSTM)\n",
    "\n",
    "**Ekstraksi Fitur:** Tokenizer + Padding\n",
    "\n",
    "**Alasan Pemilihan:**\n",
    "- LSTM sangat efektif dalam memproses data berbasis urutan, seperti teks atau kalimat.\n",
    "- Algoritma ini cocok untuk menangani long-term dependencies dalam urutan kata.\n",
    "- Tokenizer digunakan untuk mengonversi kata menjadi indeks numerik.\n",
    "- Padding digunakan untuk memastikan panjang urutan tetap sama agar dapat diproses dalam batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61fc25e",
   "metadata": {
    "id": "qyD12-NToddT"
   },
   "outputs": [],
   "source": [
    "# Tokenisasi teks dengan maksimal 10.000 kata\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(dataset['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080100fa",
   "metadata": {
    "id": "OLS-lHtb_zeG"
   },
   "outputs": [],
   "source": [
    "# Mengubah teks menjadi urutan token\n",
    "sequences = tokenizer.texts_to_sequences(dataset['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159d4d0c",
   "metadata": {
    "id": "TRM7lAwJ_220"
   },
   "outputs": [],
   "source": [
    "# Padding urutan agar memiliki panjang yang sama\n",
    "padded = pad_sequences(sequences, maxlen=100, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f503f44",
   "metadata": {
    "id": "hHnttOdfRyE-"
   },
   "outputs": [],
   "source": [
    "# Mengatasi Ketidakseimbangan Data dengan SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(padded, dataset['label_encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da6d57",
   "metadata": {
    "id": "sKqC4BEiojg9"
   },
   "outputs": [],
   "source": [
    "# Membagi data menjadi data latih dan data uji (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded, dataset['label_encoded'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241636f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09cS97VoonCA",
    "outputId": "94037db0-4904-4aa1-c1bb-1fab274c4a31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skema 1: LSTM dengan Tokenizer + Padding (80/20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Membangun Model\n",
    "print(\"\\nSkema 1: LSTM dengan Tokenizer + Padding (80/20)\")\n",
    "\n",
    "class_weights = {0: 1000, 1: 1, 2: 10}\n",
    "\n",
    "model1 = Sequential([\n",
    "    Embedding(10000, 128, input_length=100),\n",
    "    Bidirectional(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    GlobalMaxPooling1D(),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346e86f4",
   "metadata": {
    "id": "CR-EvRDvAE0n"
   },
   "outputs": [],
   "source": [
    "# Mengompilasi model dengan optimizer Adam\n",
    "model1.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f16da4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T4gCDo28AFZb",
    "outputId": "b59fd61b-8ee6-445e-80fe-45672bf7cebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 711ms/step - accuracy: 0.7042 - loss: 3.0077 - val_accuracy: 0.6939 - val_loss: 0.9136\n",
      "Epoch 2/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 727ms/step - accuracy: 0.7162 - loss: 2.0105 - val_accuracy: 0.6921 - val_loss: 0.6790\n",
      "Epoch 3/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 720ms/step - accuracy: 0.6885 - loss: 1.5884 - val_accuracy: 0.6890 - val_loss: 0.5883\n",
      "Epoch 4/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 725ms/step - accuracy: 0.7220 - loss: 1.2107 - val_accuracy: 0.7147 - val_loss: 0.5296\n",
      "Epoch 5/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 727ms/step - accuracy: 0.7228 - loss: 1.1010 - val_accuracy: 0.7704 - val_loss: 0.4286\n",
      "Epoch 6/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m678s\u001b[0m 722ms/step - accuracy: 0.7777 - loss: 0.8334 - val_accuracy: 0.8156 - val_loss: 0.3570\n",
      "Epoch 7/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 721ms/step - accuracy: 0.8497 - loss: 0.6095 - val_accuracy: 0.9255 - val_loss: 0.1743\n",
      "Epoch 8/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 722ms/step - accuracy: 0.9092 - loss: 0.5207 - val_accuracy: 0.9214 - val_loss: 0.1988\n",
      "Epoch 9/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m606s\u001b[0m 707ms/step - accuracy: 0.9185 - loss: 0.3999 - val_accuracy: 0.9365 - val_loss: 0.1589\n",
      "Epoch 10/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 710ms/step - accuracy: 0.9455 - loss: 0.3145 - val_accuracy: 0.9507 - val_loss: 0.1437\n",
      "Epoch 11/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 727ms/step - accuracy: 0.9471 - loss: 0.3682 - val_accuracy: 0.9543 - val_loss: 0.1436\n",
      "Epoch 12/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 728ms/step - accuracy: 0.9574 - loss: 0.2428 - val_accuracy: 0.9505 - val_loss: 0.1453\n",
      "Epoch 13/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 726ms/step - accuracy: 0.9483 - loss: 0.3790 - val_accuracy: 0.9643 - val_loss: 0.1181\n",
      "Epoch 14/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m668s\u001b[0m 709ms/step - accuracy: 0.9564 - loss: 0.3725 - val_accuracy: 0.9687 - val_loss: 0.1047\n",
      "Epoch 15/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 727ms/step - accuracy: 0.9719 - loss: 0.2641 - val_accuracy: 0.9392 - val_loss: 0.1833\n",
      "Epoch 16/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m686s\u001b[0m 731ms/step - accuracy: 0.9577 - loss: 0.3544 - val_accuracy: 0.9509 - val_loss: 0.1561\n",
      "Epoch 17/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m678s\u001b[0m 727ms/step - accuracy: 0.9636 - loss: 0.2407 - val_accuracy: 0.9015 - val_loss: 0.1884\n",
      "Epoch 18/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 728ms/step - accuracy: 0.9512 - loss: 0.2958 - val_accuracy: 0.8943 - val_loss: 0.2089\n",
      "Epoch 19/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 726ms/step - accuracy: 0.9416 - loss: 0.3132 - val_accuracy: 0.8894 - val_loss: 0.2275\n",
      "Epoch 20/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 728ms/step - accuracy: 0.9499 - loss: 0.3596 - val_accuracy: 0.9450 - val_loss: 0.1809\n",
      "Epoch 21/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m626s\u001b[0m 729ms/step - accuracy: 0.9764 - loss: 0.2026 - val_accuracy: 0.8862 - val_loss: 0.2491\n",
      "Epoch 22/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m686s\u001b[0m 734ms/step - accuracy: 0.9490 - loss: 0.2488 - val_accuracy: 0.8663 - val_loss: 0.3157\n",
      "Epoch 23/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m678s\u001b[0m 729ms/step - accuracy: 0.9681 - loss: 0.1524 - val_accuracy: 0.8935 - val_loss: 0.2383\n",
      "Epoch 24/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m679s\u001b[0m 725ms/step - accuracy: 0.9667 - loss: 0.2711 - val_accuracy: 0.9212 - val_loss: 0.2612\n",
      "Epoch 25/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 731ms/step - accuracy: 0.9595 - loss: 0.2892 - val_accuracy: 0.8743 - val_loss: 0.3003\n",
      "Epoch 26/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 732ms/step - accuracy: 0.9659 - loss: 0.3035 - val_accuracy: 0.8569 - val_loss: 0.3960\n",
      "Epoch 27/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 734ms/step - accuracy: 0.9576 - loss: 0.2197 - val_accuracy: 0.9214 - val_loss: 0.3137\n",
      "Epoch 28/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 732ms/step - accuracy: 0.9640 - loss: 0.1890 - val_accuracy: 0.9383 - val_loss: 0.2425\n",
      "Epoch 29/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 733ms/step - accuracy: 0.9693 - loss: 0.2479 - val_accuracy: 0.9176 - val_loss: 0.3260\n",
      "Epoch 30/30\n",
      "\u001b[1m858/858\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 730ms/step - accuracy: 0.9573 - loss: 0.2323 - val_accuracy: 0.9372 - val_loss: 0.2435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7aa6723da910>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melatih model dengan data latih\n",
    "model1.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=64, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ef9de3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebSLvWM6OD9J",
    "outputId": "0953bd95-b5a1-4b0a-ecf6-7918d69df640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluasi Model Skema 1: LSTM dengan Tokenizer + Padding (80/20)\n",
      "\u001b[1m429/429\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 92ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.01      0.60      0.01        10\n",
      "      netral       1.00      0.93      0.97     12792\n",
      "     positif       0.97      0.97      0.97       911\n",
      "\n",
      "    accuracy                           0.94     13713\n",
      "   macro avg       0.66      0.84      0.65     13713\n",
      "weighted avg       1.00      0.94      0.97     13713\n",
      "\n",
      "Akurasi Model: 0.9372\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi Model Skema 1\n",
    "print(\"\\nEvaluasi Model Skema 1: LSTM dengan Tokenizer + Padding (80/20)\")\n",
    "\n",
    "# Prediksi pada data uji\n",
    "y_pred1 = np.argmax(model1.predict(X_test), axis=1)\n",
    "\n",
    "# Laporan Klasifikasi\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred1, target_names=label_encoder.classes_))\n",
    "\n",
    "# Akurasi\n",
    "accuracy = accuracy_score(y_test, y_pred1)\n",
    "print(f\"Akurasi Model: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3faa6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M6h-PWXlhM2e",
    "outputId": "171758fd-f767-4758-948b-b51cc496ed34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inference Skema 1: LSTM dengan Tokenizer + Padding (80/20)\n",
      "\n",
      "Prediksi Teks Baru:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "Teks: I love your video!\n",
      "Prediksi Sentimen: positif\n"
     ]
    }
   ],
   "source": [
    "# Inference dan Testing Skema 1\n",
    "print(\"\\nInference Skema 1: LSTM dengan Tokenizer + Padding (80/20)\")\n",
    "# Fungsi Prediksi Teks\n",
    "def predict_text_lstm(text, tokenizer, model1, label_encoder):\n",
    "    # Tokenisasi dan padding teks\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=100, padding='post')\n",
    "\n",
    "    # Prediksi sentimen\n",
    "    prediction = model1.predict(padded_sequence)\n",
    "    label_index = np.argmax(prediction, axis=1)[0]\n",
    "    label = label_encoder.inverse_transform([label_index])[0]\n",
    "\n",
    "    print(f\"Teks: {text}\")\n",
    "    print(f\"Prediksi Sentimen: {label}\")\n",
    "\n",
    "# Prediksi Teks Baru\n",
    "print(\"\\nPrediksi Teks Baru:\")\n",
    "predict_text_lstm(\"I love your video!\", tokenizer, model1, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76313b40",
   "metadata": {
    "id": "PrDGNVEixe5m"
   },
   "source": [
    "**Insight Skema 1:**\n",
    "1. Model ini memiliki akurasi yang tinggi, mencapai 93.72%. Hal ini menunjukkan bahwa model dapat mengklasifikasikan sebagian besar teks dengan benar.\n",
    "2. Precision untuk kelas \"negatif\" sangat rendah (0.01) meskipun recall cukup tinggi (0.60). Ini menunjukkan bahwa model sering salah mengklasifikasikan teks negatif, mungkin karena data negatif sangat sedikit atau model terlalu fokus pada kelas \"netral\" dan \"positif\".\n",
    "3. Precision, recall, dan f1-score pada kelas \"netral\" dan \"positif\" sangat tinggi (mendekati 1.00). Hal ini menunjukkan bahwa model mampu mengenali kedua sentimen tersebut dengan sangat baik.\n",
    "4. Model masih memiliki kelemahan pada kelas negatif, sehingga peningkatan dapat dilakukan dengan teknik augmentasi atau modifikasi arsitektur.\n",
    "5. Pada teks uji \"I love your video!\", model berhasil mengklasifikasikannya sebagai \"positif\", yang merupakan prediksi yang tepat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82067d",
   "metadata": {},
   "source": [
    "# SKEMA 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c7f2f",
   "metadata": {
    "id": "nBwOOPI5lASL"
   },
   "source": [
    "# **2. Ekstraksi Fitur dan Pelabelan Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec230d74",
   "metadata": {
    "id": "eJv-MtsUlHzI"
   },
   "source": [
    "Metode yang digunakan bebas sesuai dengan preferensi masing-masing peserta. Tahapan ini penting untuk mempersiapkan data sehingga dapat diolah lebih lanjut dalam proses pelatihan model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edabbe8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7Uvoet4lI9T",
    "outputId": "a4a94aeb-11f8-48b5-d78a-20add4640422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi label:\n",
      "label\n",
      "netral     63770\n",
      "positif     4724\n",
      "negatif       69\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Melabeli komentar secara manual (positif, netral, negatif)\n",
    "def label_comment(text):\n",
    "    if any(word in text for word in [\"love\", \"great\", \"awesome\", \"good\", \"nice\", \"amazing\", \"fantastic\"]):\n",
    "        return \"positif\"\n",
    "    elif any(word in text for word in [\"hate\", \"bad\", \"awful\", \"worst\", \"terrible\", \"disgusting\", \"boring\"]):\n",
    "        return \"negatif\"\n",
    "    else:\n",
    "        return \"netral\"\n",
    "\n",
    "dataset['label'] = dataset['cleaned_text'].apply(label_comment)\n",
    "print(\"Distribusi label:\")\n",
    "print(dataset['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5c858",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IqZS3KMplvFC",
    "outputId": "4cc6f232-3c34-4cea-9dde-0cc9f1a707e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Setelah Encoding:\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "Classes: ['negatif' 'netral' 'positif']\n"
     ]
    }
   ],
   "source": [
    "# Encoding label\n",
    "label_encoder = LabelEncoder()\n",
    "dataset['label_encoded'] = label_encoder.fit_transform(dataset['label'])\n",
    "\n",
    "# One-Hot Encoding pada label\n",
    "y = tf.keras.utils.to_categorical(dataset['label_encoded'], num_classes=len(label_encoder.classes_))\n",
    "\n",
    "print(\"Label Setelah Encoding:\")\n",
    "print(y[:5])\n",
    "print(\"Classes:\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff50cf24",
   "metadata": {
    "id": "TMmfeaBX5Rw9"
   },
   "outputs": [],
   "source": [
    "# Tokenizer dan Padding\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(dataset['cleaned_text'])\n",
    "sequences = tokenizer.texts_to_sequences(dataset['cleaned_text'])\n",
    "padded = pad_sequences(sequences, maxlen=100, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62ec408",
   "metadata": {
    "id": "YNBGDkiA5auJ"
   },
   "outputs": [],
   "source": [
    "# Mengatasi Ketidakseimbangan Data dengan SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(padded, dataset['label_encoded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd8a473",
   "metadata": {
    "id": "97mjHYpAmZKf"
   },
   "source": [
    "# **3. Pembangunan Model Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b31c5",
   "metadata": {
    "id": "lXa9RkwLmd-C"
   },
   "source": [
    "Pilihan algoritma pelatihan ini haruslah sesuai dengan tujuan analisis sentimen yang ingin dicapai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad5d8f",
   "metadata": {
    "id": "4Ps4q2FepCEE"
   },
   "source": [
    "# Skema 2: CNN dengan Word2Vec (80/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9fad74",
   "metadata": {
    "id": "o_7WfFFd90Pk"
   },
   "source": [
    "**Algoritma:** Convolutional Neural Network (CNN)\n",
    "\n",
    "**Ekstraksi Fitur:** Word2Vec\n",
    "\n",
    "**Alasan Pemilihan:**\n",
    "- CNN dikenal dalam pengenalan pola spasial, dan bisa dimanfaatkan untuk menangkap pola lokal pada teks (misalnya n-grams).\n",
    "- Word2Vec menghasilkan representasi vektor dari kata-kata dengan mempertimbangkan hubungan semantik dan sintaksis.\n",
    "- Kombinasi CNN + Word2Vec memungkinkan model mempelajari fitur spasial dari representasi kata yang lebih kaya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba5b40",
   "metadata": {
    "id": "IJdEEgQt5e1v"
   },
   "outputs": [],
   "source": [
    "# Membagi data menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a6722",
   "metadata": {
    "id": "8CwJhTmB0GJo"
   },
   "outputs": [],
   "source": [
    "# Membuat model Word2Vec menggunakan teks bersih\n",
    "word2vec = Word2Vec(sentences=[text.split() for text in dataset['cleaned_text']], vector_size=100, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d957c2",
   "metadata": {
    "id": "QkmrFn7v0LOt"
   },
   "outputs": [],
   "source": [
    "# Menyiapkan embedding matrix\n",
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in word2vec.wv:\n",
    "        embedding_matrix[i] = word2vec.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53d75a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUuO0CUTpN6Z",
    "outputId": "7ebd177b-4533-40e3-b0c5-b6f18222e4cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Membangun model CNN\n",
    "model2 = Sequential([\n",
    "    Embedding(len(tokenizer.word_index) + 1, 100, weights=[embedding_matrix], input_length=100, trainable=False),\n",
    "    Conv1D(128, 5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc23b02",
   "metadata": {
    "id": "Tkl2QjJNBDEl"
   },
   "outputs": [],
   "source": [
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589e285",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YgQbQ3LjBC4o",
    "outputId": "ecae51a9-f399-493f-b4d5-0a78cdda795c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 46ms/step - accuracy: 0.7494 - loss: 0.6190 - val_accuracy: 0.8440 - val_loss: 0.3897\n",
      "Epoch 2/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 46ms/step - accuracy: 0.8359 - loss: 0.4196 - val_accuracy: 0.8638 - val_loss: 0.3493\n",
      "Epoch 3/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 52ms/step - accuracy: 0.8556 - loss: 0.3729 - val_accuracy: 0.8774 - val_loss: 0.3172\n",
      "Epoch 4/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 48ms/step - accuracy: 0.8664 - loss: 0.3488 - val_accuracy: 0.8786 - val_loss: 0.3077\n",
      "Epoch 5/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 46ms/step - accuracy: 0.8774 - loss: 0.3228 - val_accuracy: 0.8881 - val_loss: 0.2925\n",
      "Epoch 6/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 51ms/step - accuracy: 0.8827 - loss: 0.3106 - val_accuracy: 0.8799 - val_loss: 0.2979\n",
      "Epoch 7/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 48ms/step - accuracy: 0.8866 - loss: 0.3024 - val_accuracy: 0.8938 - val_loss: 0.2808\n",
      "Epoch 8/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 47ms/step - accuracy: 0.8930 - loss: 0.2891 - val_accuracy: 0.8963 - val_loss: 0.2795\n",
      "Epoch 9/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 46ms/step - accuracy: 0.8951 - loss: 0.2822 - val_accuracy: 0.8982 - val_loss: 0.2713\n",
      "Epoch 10/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 47ms/step - accuracy: 0.8988 - loss: 0.2734 - val_accuracy: 0.8989 - val_loss: 0.2722\n",
      "Epoch 11/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 46ms/step - accuracy: 0.9011 - loss: 0.2691 - val_accuracy: 0.9029 - val_loss: 0.2610\n",
      "Epoch 12/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 46ms/step - accuracy: 0.9022 - loss: 0.2625 - val_accuracy: 0.8996 - val_loss: 0.2661\n",
      "Epoch 13/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 46ms/step - accuracy: 0.9036 - loss: 0.2621 - val_accuracy: 0.9052 - val_loss: 0.2623\n",
      "Epoch 14/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 46ms/step - accuracy: 0.9048 - loss: 0.2568 - val_accuracy: 0.9072 - val_loss: 0.2531\n",
      "Epoch 15/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 46ms/step - accuracy: 0.9074 - loss: 0.2479 - val_accuracy: 0.9050 - val_loss: 0.2538\n",
      "Epoch 16/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 46ms/step - accuracy: 0.9086 - loss: 0.2483 - val_accuracy: 0.9084 - val_loss: 0.2539\n",
      "Epoch 17/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 46ms/step - accuracy: 0.9108 - loss: 0.2431 - val_accuracy: 0.9092 - val_loss: 0.2506\n",
      "Epoch 18/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 45ms/step - accuracy: 0.9123 - loss: 0.2375 - val_accuracy: 0.9027 - val_loss: 0.2701\n",
      "Epoch 19/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 46ms/step - accuracy: 0.9132 - loss: 0.2376 - val_accuracy: 0.9100 - val_loss: 0.2447\n",
      "Epoch 20/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 46ms/step - accuracy: 0.9140 - loss: 0.2344 - val_accuracy: 0.9082 - val_loss: 0.2472\n",
      "Epoch 21/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 46ms/step - accuracy: 0.9168 - loss: 0.2266 - val_accuracy: 0.9082 - val_loss: 0.2494\n",
      "Epoch 22/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 46ms/step - accuracy: 0.9174 - loss: 0.2255 - val_accuracy: 0.9081 - val_loss: 0.2592\n",
      "Epoch 23/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 46ms/step - accuracy: 0.9164 - loss: 0.2263 - val_accuracy: 0.9087 - val_loss: 0.2585\n",
      "Epoch 24/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 46ms/step - accuracy: 0.9178 - loss: 0.2225 - val_accuracy: 0.9120 - val_loss: 0.2407\n",
      "Epoch 25/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 47ms/step - accuracy: 0.9182 - loss: 0.2208 - val_accuracy: 0.9105 - val_loss: 0.2497\n",
      "Epoch 26/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 46ms/step - accuracy: 0.9194 - loss: 0.2192 - val_accuracy: 0.9131 - val_loss: 0.2466\n",
      "Epoch 27/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 47ms/step - accuracy: 0.9202 - loss: 0.2143 - val_accuracy: 0.9147 - val_loss: 0.2380\n",
      "Epoch 28/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 46ms/step - accuracy: 0.9220 - loss: 0.2130 - val_accuracy: 0.9103 - val_loss: 0.2518\n",
      "Epoch 29/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 47ms/step - accuracy: 0.9209 - loss: 0.2132 - val_accuracy: 0.9065 - val_loss: 0.2585\n",
      "Epoch 30/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 46ms/step - accuracy: 0.9230 - loss: 0.2090 - val_accuracy: 0.9141 - val_loss: 0.2358\n",
      "Epoch 31/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 51ms/step - accuracy: 0.9237 - loss: 0.2100 - val_accuracy: 0.9121 - val_loss: 0.2450\n",
      "Epoch 32/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 46ms/step - accuracy: 0.9246 - loss: 0.2034 - val_accuracy: 0.9110 - val_loss: 0.2483\n",
      "Epoch 33/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 52ms/step - accuracy: 0.9245 - loss: 0.2041 - val_accuracy: 0.9141 - val_loss: 0.2425\n",
      "Epoch 34/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 47ms/step - accuracy: 0.9251 - loss: 0.2033 - val_accuracy: 0.9059 - val_loss: 0.2672\n",
      "Epoch 35/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 46ms/step - accuracy: 0.9258 - loss: 0.2023 - val_accuracy: 0.9099 - val_loss: 0.2534\n",
      "Epoch 36/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 47ms/step - accuracy: 0.9258 - loss: 0.2022 - val_accuracy: 0.9123 - val_loss: 0.2488\n",
      "Epoch 37/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 47ms/step - accuracy: 0.9266 - loss: 0.2007 - val_accuracy: 0.9156 - val_loss: 0.2389\n",
      "Epoch 38/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 51ms/step - accuracy: 0.9258 - loss: 0.2011 - val_accuracy: 0.9137 - val_loss: 0.2459\n",
      "Epoch 39/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 46ms/step - accuracy: 0.9270 - loss: 0.1955 - val_accuracy: 0.9152 - val_loss: 0.2512\n",
      "Epoch 40/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 47ms/step - accuracy: 0.9285 - loss: 0.1953 - val_accuracy: 0.9110 - val_loss: 0.2556\n",
      "Epoch 41/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 47ms/step - accuracy: 0.9291 - loss: 0.1952 - val_accuracy: 0.9118 - val_loss: 0.2608\n",
      "Epoch 42/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 47ms/step - accuracy: 0.9301 - loss: 0.1918 - val_accuracy: 0.9095 - val_loss: 0.2625\n",
      "Epoch 43/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 47ms/step - accuracy: 0.9290 - loss: 0.1903 - val_accuracy: 0.9192 - val_loss: 0.2421\n",
      "Epoch 44/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 46ms/step - accuracy: 0.9302 - loss: 0.1908 - val_accuracy: 0.9153 - val_loss: 0.2396\n",
      "Epoch 45/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 47ms/step - accuracy: 0.9295 - loss: 0.1888 - val_accuracy: 0.9138 - val_loss: 0.2418\n",
      "Epoch 46/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 47ms/step - accuracy: 0.9292 - loss: 0.1919 - val_accuracy: 0.9092 - val_loss: 0.2486\n",
      "Epoch 47/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 52ms/step - accuracy: 0.9287 - loss: 0.1915 - val_accuracy: 0.9160 - val_loss: 0.2381\n",
      "Epoch 48/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 47ms/step - accuracy: 0.9308 - loss: 0.1842 - val_accuracy: 0.9127 - val_loss: 0.2532\n",
      "Epoch 49/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 47ms/step - accuracy: 0.9304 - loss: 0.1870 - val_accuracy: 0.9147 - val_loss: 0.2411\n",
      "Epoch 50/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 46ms/step - accuracy: 0.9308 - loss: 0.1872 - val_accuracy: 0.9176 - val_loss: 0.2433\n",
      "Epoch 51/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 46ms/step - accuracy: 0.9304 - loss: 0.1867 - val_accuracy: 0.9170 - val_loss: 0.2428\n",
      "Epoch 52/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 47ms/step - accuracy: 0.9322 - loss: 0.1828 - val_accuracy: 0.9157 - val_loss: 0.2515\n",
      "Epoch 53/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 46ms/step - accuracy: 0.9317 - loss: 0.1837 - val_accuracy: 0.9100 - val_loss: 0.2567\n",
      "Epoch 54/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 46ms/step - accuracy: 0.9320 - loss: 0.1829 - val_accuracy: 0.9134 - val_loss: 0.2679\n",
      "Epoch 55/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 47ms/step - accuracy: 0.9316 - loss: 0.1824 - val_accuracy: 0.9126 - val_loss: 0.2491\n",
      "Epoch 56/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 47ms/step - accuracy: 0.9326 - loss: 0.1808 - val_accuracy: 0.9164 - val_loss: 0.2600\n",
      "Epoch 57/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 46ms/step - accuracy: 0.9331 - loss: 0.1792 - val_accuracy: 0.9152 - val_loss: 0.2540\n",
      "Epoch 58/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 47ms/step - accuracy: 0.9346 - loss: 0.1764 - val_accuracy: 0.9178 - val_loss: 0.2408\n",
      "Epoch 59/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 47ms/step - accuracy: 0.9340 - loss: 0.1782 - val_accuracy: 0.9111 - val_loss: 0.2538\n",
      "Epoch 60/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 46ms/step - accuracy: 0.9335 - loss: 0.1783 - val_accuracy: 0.9181 - val_loss: 0.2642\n",
      "Epoch 61/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 48ms/step - accuracy: 0.9344 - loss: 0.1753 - val_accuracy: 0.9155 - val_loss: 0.2630\n",
      "Epoch 62/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 47ms/step - accuracy: 0.9354 - loss: 0.1737 - val_accuracy: 0.9135 - val_loss: 0.2907\n",
      "Epoch 63/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 63ms/step - accuracy: 0.9334 - loss: 0.1795 - val_accuracy: 0.9177 - val_loss: 0.2534\n",
      "Epoch 64/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 49ms/step - accuracy: 0.9349 - loss: 0.1731 - val_accuracy: 0.9177 - val_loss: 0.2551\n",
      "Epoch 65/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 47ms/step - accuracy: 0.9359 - loss: 0.1742 - val_accuracy: 0.9187 - val_loss: 0.2571\n",
      "Epoch 66/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 47ms/step - accuracy: 0.9357 - loss: 0.1732 - val_accuracy: 0.9152 - val_loss: 0.2638\n",
      "Epoch 67/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 46ms/step - accuracy: 0.9366 - loss: 0.1711 - val_accuracy: 0.9173 - val_loss: 0.2482\n",
      "Epoch 68/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 46ms/step - accuracy: 0.9359 - loss: 0.1711 - val_accuracy: 0.9191 - val_loss: 0.2532\n",
      "Epoch 69/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 47ms/step - accuracy: 0.9358 - loss: 0.1714 - val_accuracy: 0.9179 - val_loss: 0.2603\n",
      "Epoch 70/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 46ms/step - accuracy: 0.9363 - loss: 0.1720 - val_accuracy: 0.9142 - val_loss: 0.2688\n",
      "Epoch 71/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 46ms/step - accuracy: 0.9377 - loss: 0.1687 - val_accuracy: 0.9175 - val_loss: 0.2504\n",
      "Epoch 72/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 47ms/step - accuracy: 0.9371 - loss: 0.1700 - val_accuracy: 0.9168 - val_loss: 0.2563\n",
      "Epoch 73/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 47ms/step - accuracy: 0.9373 - loss: 0.1695 - val_accuracy: 0.9179 - val_loss: 0.2488\n",
      "Epoch 74/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 59ms/step - accuracy: 0.9381 - loss: 0.1658 - val_accuracy: 0.9157 - val_loss: 0.2544\n",
      "Epoch 75/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 52ms/step - accuracy: 0.9363 - loss: 0.1701 - val_accuracy: 0.9192 - val_loss: 0.2664\n",
      "Epoch 76/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 46ms/step - accuracy: 0.9371 - loss: 0.1679 - val_accuracy: 0.9183 - val_loss: 0.2517\n",
      "Epoch 77/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 47ms/step - accuracy: 0.9385 - loss: 0.1645 - val_accuracy: 0.9210 - val_loss: 0.2709\n",
      "Epoch 78/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 46ms/step - accuracy: 0.9372 - loss: 0.1663 - val_accuracy: 0.9180 - val_loss: 0.2663\n",
      "Epoch 79/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 47ms/step - accuracy: 0.9392 - loss: 0.1646 - val_accuracy: 0.9186 - val_loss: 0.2642\n",
      "Epoch 80/80\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 46ms/step - accuracy: 0.9383 - loss: 0.1657 - val_accuracy: 0.9168 - val_loss: 0.2578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7eaf631504d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, epochs=80, validation_data=(X_test, y_test), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fca90c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qRFsye-16RH-",
    "outputId": "25489075-d53e-4f76-b78a-7f159829b66e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1196/1196\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.89      0.93      0.91     12770\n",
      "      netral       0.92      0.96      0.94     12699\n",
      "     positif       0.95      0.85      0.90     12793\n",
      "\n",
      "    accuracy                           0.92     38262\n",
      "   macro avg       0.92      0.92      0.92     38262\n",
      "weighted avg       0.92      0.92      0.92     38262\n",
      "\n",
      "Akurasi Model: 0.9168\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi model pada data testing\n",
    "# Prediksi pada data uji\n",
    "y_pred1 = np.argmax(model2.predict(X_test), axis=1)\n",
    "\n",
    "# Laporan Klasifikasi\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred1, target_names=label_encoder.classes_))\n",
    "\n",
    "# Akurasi\n",
    "accuracy = accuracy_score(y_test, y_pred1)\n",
    "print(f\"Akurasi Model: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7c203",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_UsfMFfeqUJm",
    "outputId": "ebf21461-b863-4831-ae72-5f7b2139b981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inference Skema 2: CNN dengan Word2Vec (80/20)\n",
      "\n",
      "Prediksi Teks Baru:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Teks: As an egyptian, I didn't know about the Sphinx.\n",
      "Prediksi Sentimen: netral\n"
     ]
    }
   ],
   "source": [
    "# Inference dan Testing Skema 2\n",
    "print(\"\\nInference Skema 2: CNN dengan Word2Vec (80/20)\")\n",
    "# Fungsi Prediksi Teks\n",
    "def predict_text(text, tokenizer, model2, label_encoder):\n",
    "    # Tokenisasi dan padding teks\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=100, padding='post')\n",
    "\n",
    "    # Prediksi sentimen\n",
    "    prediction = model2.predict(padded_sequence)\n",
    "    label_index = np.argmax(prediction, axis=1)[0]\n",
    "    label = label_encoder.inverse_transform([label_index])[0]\n",
    "\n",
    "    print(f\"Teks: {text}\")\n",
    "    print(f\"Prediksi Sentimen: {label}\")\n",
    "\n",
    "# Prediksi Teks Baru\n",
    "print(\"\\nPrediksi Teks Baru:\")\n",
    "predict_text(\"As an egyptian, I didn't know about the Sphinx.\", tokenizer, model2, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af2dce",
   "metadata": {
    "id": "L6uFR_uK-5Fr"
   },
   "source": [
    "**Insight Skema 2 :**\n",
    "\n",
    "1. Model ini memiliki akurasi yang sangat baik, yaitu 91.68%, menunjukkan kemampuan model dalam mengklasifikasikan sentimen dengan cukup akurat.\n",
    "\n",
    "2. Kinerja Model pada Setiap Kelas\n",
    "\n",
    "- Negatif: Precision 0.89, Recall 0.93, F1-Score 0.91\n",
    "- Netral: Precision 0.92, Recall 0.96, F1-Score 0.94\n",
    "- Positif: Precision 0.95, Recall 0.85, F1-Score 0.90\n",
    "- Model memiliki keseimbangan performa yang baik di ketiga kelas, dengan sedikit penurunan pada recall kelas \"positif\".\n",
    "3. Pada teks \"As an Egyptian, I didn't know about the Sphinx.\", model memprediksi sentimen sebagai \"netral\", yang memang sesuai dengan konteks kalimat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dc9824",
   "metadata": {},
   "source": [
    "# SKEMA 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324f3698",
   "metadata": {
    "id": "nBwOOPI5lASL"
   },
   "source": [
    "# **2. Ekstraksi Fitur dan Pelabelan Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a99f334",
   "metadata": {
    "id": "eJv-MtsUlHzI"
   },
   "source": [
    "Metode yang digunakan bebas sesuai dengan preferensi masing-masing peserta. Tahapan ini penting untuk mempersiapkan data sehingga dapat diolah lebih lanjut dalam proses pelatihan model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49274969",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7Uvoet4lI9T",
    "outputId": "51fd54bc-4f3f-4802-af31-3e7f01193717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi label:\n",
      "label\n",
      "netral     63770\n",
      "positif     4724\n",
      "negatif       69\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Melabeli komentar secara manual (positif, netral, negatif)\n",
    "def label_comment(text):\n",
    "    if any(word in text for word in [\"love\", \"great\", \"awesome\", \"good\", \"nice\", \"amazing\", \"fantastic\"]):\n",
    "        return \"positif\"\n",
    "    elif any(word in text for word in [\"hate\", \"bad\", \"awful\", \"worst\", \"terrible\", \"disgusting\", \"boring\"]):\n",
    "        return \"negatif\"\n",
    "    else:\n",
    "        return \"netral\"\n",
    "\n",
    "dataset['label'] = dataset['cleaned_text'].apply(label_comment)\n",
    "print(\"Distribusi label:\")\n",
    "print(dataset['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3182ccb",
   "metadata": {
    "id": "IqZS3KMplvFC"
   },
   "outputs": [],
   "source": [
    "# Encode label dengan LabelEncoder\n",
    "le = LabelEncoder()\n",
    "dataset['label'] = le.fit_transform(dataset['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb47eb7",
   "metadata": {
    "id": "97mjHYpAmZKf"
   },
   "source": [
    "# **3. Pembangunan Model Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6245aff1",
   "metadata": {
    "id": "lXa9RkwLmd-C"
   },
   "source": [
    "Pilihan algoritma pelatihan ini haruslah sesuai dengan tujuan analisis sentimen yang ingin dicapai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23980137",
   "metadata": {
    "id": "Vp1D360LqVIn"
   },
   "source": [
    "# Skema 3: GRU dengan Word2Vec (70/30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4603dc1",
   "metadata": {
    "id": "0_wEtFsD-ODX"
   },
   "source": [
    "**Algoritma:** GRU (Gated Recurrent Unit)\n",
    "\n",
    "**Ekstraksi Fitur:** Word2Vec\n",
    "\n",
    "**Alasan Pemilihan:**\n",
    "\n",
    "- GRU lebih sederhana dan lebih ringan dibandingkan dengan LSTM, sehingga lebih cepat dalam proses pelatihan tanpa kehilangan banyak informasi temporal. Cocok untuk dataset teks dengan jumlah data besar.\n",
    "- Word2Vec digunakan untuk menghasilkan vektor kata yang memiliki makna semantik sehingga model dapat memahami konteks dari kata-kata dalam kalimat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fd8e83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FyX2y7Fqd1i",
    "outputId": "0e69a0d1-f2f5-488f-8118-2e3a3aadfb37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skema 3: GRU dengan Word2Vec (70/30)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSkema 3: GRU dengan Word2Vec (70/30)\")\n",
    "# Split data 70/30\n",
    "X = dataset['cleaned_text']\n",
    "y = dataset['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f520abe",
   "metadata": {
    "id": "_j0tircbPPiN"
   },
   "outputs": [],
   "source": [
    "# Tokenizer dan Padding\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)  # Hanya fit pada data latih untuk mencegah data bocor\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Padding\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=209, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=209, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc6f9e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIaTRLE6htne",
    "outputId": "19f171ae-a97e-40e7-9164-1e029796ef62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi label setelah SMOTE:\n",
      "label\n",
      "1    44619\n",
      "2    44619\n",
      "0    44619\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mengatasi Ketidakseimbangan Data dengan SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_padded, y_train)\n",
    "\n",
    "print(\"Distribusi label setelah SMOTE:\")\n",
    "print(pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e63461",
   "metadata": {
    "id": "brElYiJWPXb6"
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding pada label\n",
    "encoder = LabelEncoder()\n",
    "y_resampled_encoded = encoder.fit_transform(y_resampled)  # Transform label SMOTE\n",
    "y_test_encoded = encoder.transform(y_test)  # Transform label uji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5de38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKFQ6SspUwCp",
    "outputId": "5bfe1e66-3c29-45ec-8618-d53c0471e520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Setelah One-Hot Encoding:\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n",
      "Classes: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding\n",
    "y_resampled_encoded = tf.keras.utils.to_categorical(y_resampled_encoded, num_classes=3)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test_encoded, num_classes=3)\n",
    "\n",
    "print(\"Label Setelah One-Hot Encoding:\")\n",
    "print(y_resampled_encoded[:5])\n",
    "print(\"Classes:\", encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a20e19",
   "metadata": {
    "id": "YZFjHTkWqeuk"
   },
   "outputs": [],
   "source": [
    "# Model GRU\n",
    "model3 = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=209),  # Embedding layer lebih kecil\n",
    "    Bidirectional(GRU(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)),  # GRU lebih kecil\n",
    "    GlobalMaxPooling1D(),  # Pooling\n",
    "    BatchNormalization(),  # Normalisasi batch\n",
    "    Dropout(0.3),  # Dropout lebih rendah\n",
    "    Dense(64, activation='relu'),  # Layer Dense lebih kecil\n",
    "    Dropout(0.3),  # Dropout lebih rendah\n",
    "    Dense(32, activation='relu'),  # Layer Dense lebih kecil\n",
    "    Dropout(0.3),  # Dropout lagi\n",
    "    Dense(3, activation='softmax')  # Output layer dengan 3 kelas\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f23d9ce",
   "metadata": {
    "id": "oglGMxxdBOoD"
   },
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d5e9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wurPNkJ4XHHs",
    "outputId": "8d75575d-e39d-4ad0-c080-2aceb4412673"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1219s\u001b[0m 583ms/step - accuracy: 0.9227 - loss: 0.2071 - val_accuracy: 0.9725 - val_loss: 0.1052\n",
      "Epoch 2/10\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1227s\u001b[0m 585ms/step - accuracy: 0.9344 - loss: 0.1814 - val_accuracy: 0.9698 - val_loss: 0.1081\n",
      "Epoch 3/10\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1205s\u001b[0m 576ms/step - accuracy: 0.9424 - loss: 0.1597 - val_accuracy: 0.9700 - val_loss: 0.1204\n",
      "Epoch 4/10\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1202s\u001b[0m 575ms/step - accuracy: 0.9476 - loss: 0.1458 - val_accuracy: 0.9578 - val_loss: 0.1437\n",
      "Epoch 5/10\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1219s\u001b[0m 573ms/step - accuracy: 0.9534 - loss: 0.1327 - val_accuracy: 0.9736 - val_loss: 0.1010\n",
      "Epoch 6/10\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1254s\u001b[0m 589ms/step - accuracy: 0.9583 - loss: 0.1194 - val_accuracy: 0.9632 - val_loss: 0.1492\n",
      "Epoch 7/10\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1259s\u001b[0m 578ms/step - accuracy: 0.9602 - loss: 0.1150 - val_accuracy: 0.9736 - val_loss: 0.1047\n",
      "Epoch 8/10\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1197s\u001b[0m 566ms/step - accuracy: 0.9639 - loss: 0.1052 - val_accuracy: 0.9632 - val_loss: 0.1349\n",
      "Epoch 9/10\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1170s\u001b[0m 559ms/step - accuracy: 0.9658 - loss: 0.0983 - val_accuracy: 0.9675 - val_loss: 0.1386\n",
      "Epoch 10/10\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1214s\u001b[0m 556ms/step - accuracy: 0.9685 - loss: 0.0911 - val_accuracy: 0.9705 - val_loss: 0.1223\n"
     ]
    }
   ],
   "source": [
    "# Melatih model dengan data seimbang\n",
    "history = model3.fit(\n",
    "    X_resampled, y_resampled_encoded,  # Data dan label sudah One-Hot\n",
    "    epochs=10,\n",
    "    validation_data=(X_test_padded, y_test_encoded),  # Data validasi juga One-Hot\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b8a532",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8t5QY8K06muf",
    "outputId": "7a2013c0-bb95-4ed9-a2c6-8f3b123cb555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 80ms/step - accuracy: 0.9723 - loss: 0.1182\n",
      "Akurasi Testing (dari model.evaluate): 97.05%\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data testing\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=209, padding='post')\n",
    "\n",
    "# Evaluasi model pada data testing\n",
    "test_loss, test_accuracy = model3.evaluate(X_test_padded, y_test_encoded)\n",
    "print(f\"Akurasi Testing (dari model.evaluate): {test_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb4e339",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3Bgox8yfpT8",
    "outputId": "49b08d5a-8688-4f5f-bd38-964f4a44fdce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2']\n"
     ]
    }
   ],
   "source": [
    "target_names = [str(cls) for cls in le.classes_]\n",
    "print(target_names)  # Pastikan hasilnya dalam bentuk list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ceea2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSJQ4dOTfe5O",
    "outputId": "7174eca4-68df-48e8-ffa5-aec36fce8678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[0 1 2]\n",
      "[np.int64(0), np.int64(1), np.int64(2)]\n"
     ]
    }
   ],
   "source": [
    "print(type(le.classes_))\n",
    "print(le.classes_)\n",
    "print(list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74747113",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JglADpySeOM2",
    "outputId": "507b09f7-cdde-43ba-b635-27eab956c4e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 81ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.42      0.04        12\n",
      "           1       1.00      0.97      0.98     19151\n",
      "           2       0.80      0.97      0.87      1406\n",
      "\n",
      "    accuracy                           0.97     20569\n",
      "   macro avg       0.61      0.78      0.63     20569\n",
      "weighted avg       0.98      0.97      0.98     20569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediksi pada data testing\n",
    "y_pred2 = np.argmax(model3.predict(X_test_padded), axis=1)\n",
    "y_true = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767d5151",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xQu21Vcqhwt",
    "outputId": "164ca365-ebf1-452d-a01a-1fcdcfd6fc2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inference Skema 3: GRU dengan Word2Vec (70/30)\n"
     ]
    }
   ],
   "source": [
    "# Inference  Skema 3\n",
    "print(\"\\nInference Skema 3: GRU dengan Word2Vec (70/30)\")\n",
    "def predict_text(text, tokenizer, model3, le, max_length=100):\n",
    "    # Preprocessing teks\n",
    "    text = text.lower()\n",
    "    text_seq = tokenizer.texts_to_sequences([text])\n",
    "    text_pad = pad_sequences(text_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "    # Prediksi\n",
    "    prediction = model3.predict(text_pad)\n",
    "    predicted_label = np.argmax(prediction, axis=1)[0]\n",
    "    predicted_class = le.inverse_transform([predicted_label])[0]\n",
    "\n",
    "    print(f\"Teks: {text}\")\n",
    "    print(f\"Prediksi Label: {predicted_class}\")\n",
    "    print(f\"Confidence: {np.max(prediction) * 100:.2f}%\")\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419bb803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8o4sUiuhubdX",
    "outputId": "81f33197-c701-423a-8c40-ac5d1f3e5ae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Teks: i love how you guys taking the video, that was amazing!\n",
      "Prediksi Label: 2\n",
      "Confidence: 100.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan Prediksi pada Teks Baru (0: Negatif, 1: Netral, 2: Positif)\n",
    "predict_text(\"I love how you guys taking the video, that was amazing!\", tokenizer, model3, le)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5485e86d",
   "metadata": {
    "id": "YyASQxddzH38"
   },
   "source": [
    "**Insight Skema 3:**\n",
    "\n",
    "1. Model memiliki akurasi tinggi sebesar 97.05%, yang menunjukkan bahwa model secara keseluruhan cukup andal dalam mengklasifikasikan data.\n",
    "2. **Kelas 0 (Negatif):**\n",
    "\n",
    "- Precision: 0.02 (Sangat rendah)\n",
    "\n",
    "- Recall: 0.42 (Cukup tinggi untuk jumlah data yang sedikit)\n",
    "\n",
    "- F1-Score: 0.04 (Buruk)\n",
    "\n",
    "- Jumlah data: 12 (Sangat sedikit)\n",
    "\n",
    "- **Catatan:** Model mengalami kesulitan dalam mengklasifikasikan kelas ini karena jumlah sampel yang sangat sedikit sehingga model cenderung mengabaikannya.\n",
    "\n",
    "3. **Kelas 1 (Netral):**\n",
    "\n",
    "- Precision: 1.00 (Sangat baik)\n",
    "\n",
    "- Recall: 0.97 (Sangat baik)\n",
    "\n",
    "- F1-Score: 0.98 (Sangat tinggi)\n",
    "\n",
    "- Jumlah data: 19,151 (Mayoritas data)\n",
    "\n",
    "- **Catatan:** Model sangat akurat dalam mendeteksi kelas ini karena data yang melimpah\n",
    "\n",
    "4. **Kelas 2 (Positif):**\n",
    "\n",
    "- Precision: 0.80 (Baik)\n",
    "\n",
    "- Recall: 0.97 (Sangat baik)\n",
    "\n",
    "- F1-Score: 0.87 (Tinggi)\n",
    "\n",
    "- Jumlah data: 1,406 (Cukup banyak)\n",
    "\n",
    "- **Catatan**: Model juga mampu menangani kelas positif dengan cukup baik.\n",
    "\n",
    "5. Model memprediksi teks \"i love how you guys taking the video, that was amazing!\" sebagai kelas 2 (Positif) dengan 100% confidence."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
